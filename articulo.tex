
\documentclass{article}

% Esto es para poder escribir acentos directamente:
\usepackage[latin1]{inputenc}
% Esto es para que el LaTeX sepa que el texto est� en espa�ol:
\usepackage[spanish]{babel}

% Paquetes de la AMS:
\usepackage{amsmath, amsthm, amsfonts}

% Teoremas
%--------------------------------------------------------------------------
\newtheorem{thm}{Teorema}[section]
\newtheorem{cor}[thm]{Corolario}
\newtheorem{lem}[thm]{Lema}
\newtheorem{prop}[thm]{Proposici�n}
\theoremstyle{definition}
\newtheorem{defn}[thm]{Definici�n}
\theoremstyle{remark}
\newtheorem{rem}[thm]{Observaci�n}

% Atajos.
% Se pueden definir comandos nuevos para acortar cosas que se usan
% frecuentemente. Como ejemplo, aqu� se definen la R y la Z dobles que
% suelen representar a los conjuntos de n�meros reales y enteros.
%--------------------------------------------------------------------------

\def\RR{\mathbb{R}}
\def\ZZ{\mathbb{Z}}

% De la misma forma se pueden definir comandos con argumentos. Por
% ejemplo, aqu� definimos un comando para escribir el valor absoluto
% de algo m�s f�cilmente.
%--------------------------------------------------------------------------
\newcommand{\abs}[1]{\left\vert#1\right\vert}

% Operadores.
% Los operadores nuevos deben definirse como tales para que aparezcan
% correctamente. Como ejemplo definimos en jacobiano:
%--------------------------------------------------------------------------
\DeclareMathOperator{\Jac}{Jac}

%--------------------------------------------------------------------------
\title{Aprendizaje no supervisado}
\author{Renzo Moreno, Gary Calle, Leonardo Acevedo, Tommy Morales,\\ Hern\'an Condori \\
  \small Uiversidad Privada de Tacna\\
 % \small E12345\\
  \small Per\'u
}

\begin{document}
\maketitle

\abstract{Esto es una plantilla simple para un art\'iculo en \LaTeX.}

% INTRODUCCION
\section{Introducc\'ion}

% en esta seccion agregar su parte--------------------------------------------------------------
El funcionamiento del machine learning y sus dos modalidades son muy fáciles de comprender. Pero, ¿cómo estos algoritmos pueden aplicarse en la vida real? Aunque cualquier particular puede desarrollar diferentes mecanismos simples y aplicarlos con algunos programas informáticos, lo mejor es obtener softwares que hagan todo el trabajo por ti, como los que ofrece WorkFusion.
A diferencia del aprendizaje supervisado, en el no supervisado solo se le otorgan las características, sin proporcionarle al algoritmo ninguna etiqueta. Su función es la agrupación, por lo que el algoritmo debería catalogar por similitud y poder crear grupos, sin tener la capacidad de definir cómo es cada individualidad de cada uno de los integrantes del grupo.
\begin{equation}\\label{eq:area}
  S = \pi r^2
\end{equation}
Uno puede referirse a ecuaciones as�: ver ecuaci�n (\ref{eq:area}).
Tambi�n se pueden mencionar secciones de la misma forma: ver secci�n
\ref{sec:nada}. O citar algo de la bibliograf�a: \cite{Cd94}.
%------------------------------------------------------------------------------------------------------

\subsection{Subsection}\label{sec:nada}

M�s texto.

\subsubsection{Subsubsection}\label{sec:nada2}

M�s texto.







% OBJETIVOS
\section{Objetivos}

% en esta seccion agregar su parte--------------------------------------------------------------
Cualquier programa que aplique la machine learning puede simplificar trabajos de bases de datos y por tanto, ahorrarle a muchos empleados centenares de horas de trabajo. Además, se está involucrando activamente la automatización cognitiva, que incluye a imágenes y documentos no estructurados, lo que amplía aún más las capacidades de agrupación, clasificación y regresión.
\begin{equation}\\label{eq:area}
  S = \pi r^2
\end{equation}
Uno puede referirse a ecuaciones as�: ver ecuaci�n (\ref{eq:area}).
Tambi�n se pueden mencionar secciones de la misma forma: ver secci�n
\ref{sec:nada}. O citar algo de la bibliograf�a: \cite{Cd94}.
%------------------------------------------------------------------------------------------------------

\subsection{Subsection}\label{sec:nada}

M�s texto.

\subsubsection{Subsubsection}\label{sec:nada2}

M�s texto.





% MARCO TEORICO
\section{Marco Te\'orico}

% en esta seccion agregar su parte--------------------------------------------------------------
prendizaje no supervisado es un método de Aprendizje Automático donde un modelo es ajustado a las observaciones. Se distingue del Aprendizaje Supervisado por el hecho de que no hay un conocimiento a priori. En el aprendizaje no supervisado, un conjunto de datos de objetos de entrada es tratado. Así, el aprendizaje no supervisado típicamente trata los objetos de entrada como un conjunto de variables aleatorias, siendo construido un modelo de densidad para el conjunto de datos. \\

El aprendizaje no supervisado puede ser usado en conjunto con la inferencia bayesiana para producir probabilidades condicionales (es decir, aprendizaje supervisado) para cualquiera de las variables aleatorias dadas. El Santo Grial del aprendizaje no supervisado es la creación de un código factorial de los datos, esto es, un código con componentes estadísticamente independientes. El aprendizaje supervisado normalmente funciona mucho mejor cuando los datos iniciales son primero traducidos en un código factorial.\\

Los algoritmos de aprendizaje no supervisado suelen ser de dos tipos: \\

Aprendizaje hebbiano : pretende medir la familiaridad o extraer características de los datos de entrada. Este aprendizaje consiste básicamente en el ajuste de los pesos de las conexiones de acuerdo con la correlación de los valores de activación (salidas) de las dos neuronas conectadas : \\

\begin{equation}\\l
  Incr (wji) = yi yj
\end{equation}

Si las dos unidades son activas (salida positiva), se produce un reforzamiento de la conexión. Si por el contrario, una es activa y la otra pasiva (salida negativa), se produce un debilitamiento de la conexión. Por tanto, la modificación de los pesos se realiza en función de los estados (salidas) de las neuronas, obtenidos tras la presentación de cierto estímulo (información de entrada), sin tener en cuenta si se deseaba obtener o no esos estados de activación.\\
Este tipo de aprendizaje se utiliza en la RED HOPFIELD (1982), ADDITIVE GROSSBERG (1973), LEARNING MATRIX (1961), BIDIRECTIONAL ASSOCIATIVE MEMORY (1988), TEMPORAL ASSOCIATIVE MEMORY (1972). Estas dos últimas son redes feedforward/feedback de 2 capas.\\
Aprendizaje competitivo y cooperativo : las neuronas compiten unas con otras con el fin de llevar a cabo una tarea dada. Se pretende que cuando se presente a la red cierta información, sólo una o un grupo de ellas se activen. Por tanto las neuronas compiten por activarse, quedando las perdedoras a sus valores de respuesta mínimos. La conexión entre neuronas se realiza en todas las capas de la red, existiendo en estas neuronas conexiones recurrentes de autoexcitación y conexiones de inhibición (signo negativo) por parte de neuronas vecinas.

%------------------------------------------------------------------------------------------------------

\subsection{Subsection}\label{sec:nada}

M�s texto.

\subsubsection{Subsubsection}\label{sec:nada2}

M�s texto.





% EJEMPLO
\section{Ejemplo}

% en esta seccion agregar su parte--------------------------------------------------------------
El ejemplo clásico de aprendizaje no supervisado en el estudio de redes neuronales es el principio de Donald Hebb, es decir, las neuronas que se unen se conectan entre sí. En el aprendizaje de Hebbian, la conexión se refuerza independientemente de un error, pero es exclusivamente una función de la coincidencia entre los potenciales de acción entre las dos neuronas. Una versión similar que modifica los pesos sinápticos toma en cuenta el tiempo entre los potenciales de acción (plasticidad dependiente del tiempo de espiga o STDP). Se ha planteado la hipótesis de que Hebbian Learning subyace en una serie de funciones cognitivas, como el reconocimiento de patrones y el aprendizaje experiencial.
%------------------------------------------------------------------------------------------------------

\subsection{Subsection}\label{sec:nada}

M�s texto.

\subsubsection{Subsubsection}\label{sec:nada2}

M�s texto.




% ANNALISIS
\section{An\'alisis}

% en esta seccion agregar su parte--------------------------------------------------------------
llenar aqui el texto de introduccion
\begin{equation}\\label{eq:area}
  S = \pi r^2
\end{equation}
Uno puede referirse a ecuaciones as�: ver ecuaci�n (\ref{eq:area}).
Tambi�n se pueden mencionar secciones de la misma forma: ver secci�n
\ref{sec:nada}. O citar algo de la bibliograf�a: \cite{Cd94}.
%------------------------------------------------------------------------------------------------------

\subsection{Subsection}\label{sec:nada}

M�s texto.

\subsubsection{Subsubsection}\label{sec:nada2}

M�s texto.






% CONCLUSIONES
\section{Conclusiones}

% en esta seccion agregar su parte--------------------------------------------------------------
llenar aqui el texto de introduccion
\begin{equation}\\label{eq:area}
  S = \pi r^2
\end{equation}
Uno puede referirse a ecuaciones as�: ver ecuaci�n (\ref{eq:area}).
Tambi�n se pueden mencionar secciones de la misma forma: ver secci�n
\ref{sec:nada}. O citar algo de la bibliograf�a: \cite{Cd94}.
%------------------------------------------------------------------------------------------------------

\subsection{Subsection}\label{sec:nada}

M�s texto.

\subsubsection{Subsubsection}\label{sec:nada2}

M�s texto.





% BIBLIOGRAFIA
\section{Bibliograf\'ia}

% en esta seccion agregar su parte--------------------------------------------------------------
llenar aqui el texto de introduccion








% Bibliograf�a.
%-----------------------------------------------------------------
\begin{thebibliography}{99}

\bibitem{Cd94} Autor, \emph{T\'itulo}, Revista/Editor, (ano)

\end{thebibliography}

\end{document}